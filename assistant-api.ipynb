{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.3.7)\n",
      "Collecting openai\n",
      "  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m461.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.10.7)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.7\n",
      "    Uninstalling openai-1.3.7:\n",
      "      Successfully uninstalled openai-1.3.7\n",
      "Successfully installed openai-1.3.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI-API-KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Math tutor\",\n",
    "  instructions=\"you are a personal math tutor, write and run code to answer math questions.\",\n",
    "  tools=[{\"type\":\"code_interpreter\"}],\n",
    "  model=\"gpt-4-1106-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_YeTPy5KlB9GF4FCL83YtUHc3', created_at=1702278736, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"I need to solve the equation `3x+11=14`,can you help me?\"\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_yzXU9FHarhQCvOwdjI1iTXo5', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x+11=14`,can you help me?'), type='text')], created_at=1702278738, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3')\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"solve the equation `3x+11=14`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_78LT2vwUs6ov3nnhBinGnAGj', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', cancelled_at=None, completed_at=None, created_at=1702278743, expires_at=1702279343, failed_at=None, file_ids=[], instructions='solve the equation `3x+11=14`', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3', tools=[ToolAssistantToolsCode(type='code_interpreter')])\n"
     ]
    }
   ],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id,\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_nOVq2KBB9SvWlHJ7HEg1igxb', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).'), type='text')], created_at=1702278758, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_78LT2vwUs6ov3nnhBinGnAGj', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_yzXU9FHarhQCvOwdjI1iTXo5', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x+11=14`,can you help me?'), type='text')], created_at=1702278738, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3')], object='list', first_id='msg_nOVq2KBB9SvWlHJ7HEg1igxb', last_id='msg_yzXU9FHarhQCvOwdjI1iTXo5', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id,\n",
    ")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: I need to solve the equation `3x+11=14`,can you help me?\n",
      "assistant: The solution to the equation \\(3x + 11 = 14\\) is \\(x = 1\\).\n"
     ]
    }
   ],
   "source": [
    "for message in reversed(messages.data):\n",
    "  print(message.role + \": \" + message.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file = open(\"motor production since 2000.xlsx\", \"rb\"),\n",
    "  purpose = \"assistants\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.\",\n",
    "  file_ids=[file.id],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id,\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_iZ2HTZ61JRPdUED6dmYGXAgK', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value='The top 10 countries with the highest motor production in 2022 are:\\n\\n1. China: 27,020,615\\n2. USA: 10,060,339\\n3. Japan: 7,835,519\\n4. India: 5,456,857\\n5. South Korea: 3,757,049\\n6. Germany: 3,677,820\\n7. Mexico: 3,509,072\\n8. Brazil: 2,369,769\\n9. Spain: 2,219,462\\n10. Thailand: 1,883,515\\n\\nThese figures represent the total motor production (including cars and commercial vehicles) for each of the listed countries in 2022.'), type='text')], created_at=1702278920, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dRKOc3suntIP1o5pZaFjd3cc', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_NCzcOYpdvVtV4RVoFOLpSd1h', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value=\"The data contains production volumes by year, with the following columns:\\n\\n1. Year (column named 'production volumes')\\n2. Country/Region\\n3. Cars (production volume)\\n4. Commercial Vehicles (production volume)\\n5. Total production volume\\n\\nSince we are interested in the top 10 countries with the highest motor production in 2022, we will focus on the year 2022 and the total production volume. Let's filter the data for 2022 and sort the countries by their total production volume to find the top 10.\"), type='text')], created_at=1702278890, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dRKOc3suntIP1o5pZaFjd3cc', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_k9m2WQ1sBCTy9Ktn6shYl7Zl', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value=\"The file has been successfully loaded as an Excel file. Now, let's analyze the data to identify the top 10 countries with the highest motor production in 2022.\"), type='text')], created_at=1702278881, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dRKOc3suntIP1o5pZaFjd3cc', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_bGmo7COTRZQv6qXHuhCLYcGr', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value=\"It looks like I encountered an error because I did not manage to load the file correctly. This might have happened because the file lacks an extension in its name, which prevents me from determining the format automatically.\\n\\nTo address this, I will try different methods to load the file as it could be in a common tabular data format like CSV or Excel. Let's start by attempting to read it as a CSV and then as an Excel file. If both attempts fail, we'll need to investigate further.\"), type='text')], created_at=1702278864, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dRKOc3suntIP1o5pZaFjd3cc', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_8J5SlxoZp6ZO5ab6njbHGMlo', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value=\"I will begin by analyzing the content of the uploaded file to determine the structure of the data. Once I have a better understanding of the data, I can extract information about the motor production for different countries in 2022 and identify the top 10 countries with the highest production. Let's start by analyzing the file.\"), type='text')], created_at=1702278819, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dRKOc3suntIP1o5pZaFjd3cc', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_YtfOZANZUmUa28DTvxTqen9n', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.'), type='text')], created_at=1702278814, file_ids=['file-dtLsRyEd3Dr7RmwH8goMjN7F'], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_1btSn2YqVbB9XbBhYPNa1ChN', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.'), type='text')], created_at=1702278778, file_ids=['file-4yfTCmsiITxGmxUNWb5IXxvc'], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_nOVq2KBB9SvWlHJ7HEg1igxb', assistant_id='asst_wv5IK7bShWnXTHaijpMAhE0d', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).'), type='text')], created_at=1702278758, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_78LT2vwUs6ov3nnhBinGnAGj', thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3'), ThreadMessage(id='msg_yzXU9FHarhQCvOwdjI1iTXo5', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x+11=14`,can you help me?'), type='text')], created_at=1702278738, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YeTPy5KlB9GF4FCL83YtUHc3')], object='list', first_id='msg_iZ2HTZ61JRPdUED6dmYGXAgK', last_id='msg_yzXU9FHarhQCvOwdjI1iTXo5', has_more=False)\n",
      "user: I need to solve the equation `3x+11=14`,can you help me?\n",
      "assistant: The solution to the equation \\(3x + 11 = 14\\) is \\(x = 1\\).\n",
      "user: anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.\n",
      "user: anayle the data I uploaded, and tell me the top 10 countries with the highest motor production in 2022.\n",
      "assistant: I will begin by analyzing the content of the uploaded file to determine the structure of the data. Once I have a better understanding of the data, I can extract information about the motor production for different countries in 2022 and identify the top 10 countries with the highest production. Let's start by analyzing the file.\n",
      "assistant: It looks like I encountered an error because I did not manage to load the file correctly. This might have happened because the file lacks an extension in its name, which prevents me from determining the format automatically.\n",
      "\n",
      "To address this, I will try different methods to load the file as it could be in a common tabular data format like CSV or Excel. Let's start by attempting to read it as a CSV and then as an Excel file. If both attempts fail, we'll need to investigate further.\n",
      "assistant: The file has been successfully loaded as an Excel file. Now, let's analyze the data to identify the top 10 countries with the highest motor production in 2022.\n",
      "assistant: The data contains production volumes by year, with the following columns:\n",
      "\n",
      "1. Year (column named 'production volumes')\n",
      "2. Country/Region\n",
      "3. Cars (production volume)\n",
      "4. Commercial Vehicles (production volume)\n",
      "5. Total production volume\n",
      "\n",
      "Since we are interested in the top 10 countries with the highest motor production in 2022, we will focus on the year 2022 and the total production volume. Let's filter the data for 2022 and sort the countries by their total production volume to find the top 10.\n",
      "assistant: The top 10 countries with the highest motor production in 2022 are:\n",
      "\n",
      "1. China: 27,020,615\n",
      "2. USA: 10,060,339\n",
      "3. Japan: 7,835,519\n",
      "4. India: 5,456,857\n",
      "5. South Korea: 3,757,049\n",
      "6. Germany: 3,677,820\n",
      "7. Mexico: 3,509,072\n",
      "8. Brazil: 2,369,769\n",
      "9. Spain: 2,219,462\n",
      "10. Thailand: 1,883,515\n",
      "\n",
      "These figures represent the total motor production (including cars and commercial vehicles) for each of the listed countries in 2022.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id,\n",
    ")\n",
    "print(messages)\n",
    "for message in reversed(messages.data):\n",
    "  print(message.role + \": \" + message.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file = open(\"RAG.docx\", \"rb\"),\n",
    "  purpose = \"assistants\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_forretrieval = client.beta.assistants.create(\n",
    "  name=\"llm expert\",\n",
    "  description=\"you are an expert in LLM, good at answering questions about AI\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\":\"retrieval\"}],\n",
    "  file_ids=[file.id],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_forretrieval = client.beta.threads.create(\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread_forretrieval.id,\n",
    "  role=\"user\",\n",
    "  content=\"what is RAG?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread_forretrieval.id,\n",
    "  assistant_id=assistant_forretrieval.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread_forretrieval.id,\n",
    "  run_id=run.id,\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_vRuS6yjmOiQ5qT4xke0Klj7p', assistant_id='asst_5BuGUt25ZqLpLrOtprjCcoXr', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=503, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-LPTUXTdsFfbgJNmPi2mutIZb', quote='Retrieval augmented generation (RAG) is a strategy that helps address both of these issues pairing information retrieval with a set of carefully designed system prompts to anchor LLMs on precise up-to-date and pertinent information retrieved from an external knowledge store. Prompting LLMs with this contextual knowledge makes it possible to create domain-specific applications that require a deep and evolving understanding of facts despite LLM training data remaining static'), start_index=493, text='【7†source】', type='file_citation')], value='RAG stands for Retrieval Augmented Generation. It is a strategy that combines information retrieval with a set of carefully designed system prompts, which are then used to guide language model predictions with precise, up-to-date, and relevant information retrieved from an external knowledge base. This approach helps create domain-specific applications that can understand and generate content based on facts which continue to evolve, even if the language model training data does not change【7†source】.'), type='text')], created_at=1701772464, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_8fRJQbqrMXAXIQZsu3hCbE6L', thread_id='thread_OPkLLvrhfWtBMnS1Mj8qP3Ey'), ThreadMessage(id='msg_CSHXwIVo0viXX7xBTFclJKf2', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what is RAG?'), type='text')], created_at=1701771799, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_OPkLLvrhfWtBMnS1Mj8qP3Ey')], object='list', first_id='msg_vRuS6yjmOiQ5qT4xke0Klj7p', last_id='msg_CSHXwIVo0viXX7xBTFclJKf2', has_more=False)\n",
      "user: what is RAG?\n",
      "assistant: RAG stands for Retrieval Augmented Generation. It is a strategy that combines information retrieval with a set of carefully designed system prompts, which are then used to guide language model predictions with precise, up-to-date, and relevant information retrieved from an external knowledge base. This approach helps create domain-specific applications that can understand and generate content based on facts which continue to evolve, even if the language model training data does not change【7†source】.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread_forretrieval.id,\n",
    ")\n",
    "print(messages)\n",
    "for message in reversed(messages.data):\n",
    "  print(message.role + \": \" + message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
